{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "S3GA0QSbiglT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LjpwuK_h88KW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as dataloader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define data transformations for training and validation"
      ],
      "metadata": {
        "id": "7o0fhfrJinmp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2QEVtN3F90ne"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load FashionMNIST datasets for training and validation"
      ],
      "metadata": {
        "id": "5WUijkrYitRB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "f9iIZ_Kf9IhD"
      },
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.FashionMNIST(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=train_transform\n",
        ")\n",
        "val_dataset = torchvision.datasets.FashionMNIST(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=val_transform\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display example image and label from the training dataset"
      ],
      "metadata": {
        "id": "CPGQS11WiyK7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EzDgZzRwART",
        "outputId": "6e940fce-c81f-4d5f-cc1e-8d49bdb138e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28]) 9\n"
          ]
        }
      ],
      "source": [
        "img, label = train_dataset[0]\n",
        "print(img.shape, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup constants and hyperparameters"
      ],
      "metadata": {
        "id": "G7eHYiVhizq1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8YeRKHcq_VSs"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "img_size = 28\n",
        "patch_size = 4\n",
        "num_channels = 1\n",
        "num_patches = (img_size // patch_size) ** 2\n",
        "embed_dim = 128\n",
        "num_heads = 4\n",
        "mlp_dim = 256\n",
        "transformer_units = 6\n",
        "dropout_rate = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create DataLoader objects for training and validation datasets"
      ],
      "metadata": {
        "id": "RKwsE78Ti18F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9TPMWJXIBT0m"
      },
      "outputs": [],
      "source": [
        "train_data = dataloader.DataLoader(train_dataset ,shuffle =True ,batch_size = batch_size)\n",
        "val_data = dataloader.DataLoader(val_dataset ,shuffle =True ,batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize one batch of images and their patch embedding"
      ],
      "metadata": {
        "id": "JNoM-bT9i6Z9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAOxvLzsXOFS",
        "outputId": "917100b4-bf0b-4a86-ae59-af30fec13230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of images in a batch: torch.Size([64, 1, 28, 28])\n",
            "Shape of embedded data: torch.Size([64, 49, 128])\n",
            "torch.Size([1, 1, 128])\n"
          ]
        }
      ],
      "source": [
        "images, labels = next(iter(val_data))\n",
        "print(\"Shape of images in a batch:\", images.shape)\n",
        "patch_embed = nn.Conv2d(num_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "embedded_data = patch_embed(images)\n",
        "embedded_data = embedded_data.flatten(2)\n",
        "embedded_data = embedded_data.transpose(1,2)\n",
        "print(\"Shape of embedded data:\", embedded_data.shape)\n",
        "print(torch.randn(1,1,embed_dim).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Patch Embedding module"
      ],
      "metadata": {
        "id": "9HgQ-0yZi-ik"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SHgnkLHwBUe1"
      },
      "outputs": [],
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.patch_embed = nn.Conv2d(\n",
        "            in_channels=num_channels,\n",
        "            out_channels=embed_dim,\n",
        "            kernel_size=patch_size,\n",
        "            stride=patch_size\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        x = x.flatten(2)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Transformer block module"
      ],
      "metadata": {
        "id": "c0U3uQ9njCd2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "76nsfHQiDjLi"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer_norm_1 = nn.LayerNorm(\n",
        "            normalized_shape=embed_dim,\n",
        "            eps=1e-5,\n",
        "            elementwise_affine=True\n",
        "        )\n",
        "        self.self_attention = nn.MultiheadAttention(\n",
        "            embed_dim=embed_dim,\n",
        "            num_heads=num_heads,\n",
        "            dropout=0.0,\n",
        "            batch_first=True,\n",
        "            bias=True\n",
        "        )\n",
        "        self.layer_norm_2 = nn.LayerNorm(\n",
        "            normalized_shape=embed_dim,\n",
        "            eps=1e-5,\n",
        "            elementwise_affine=True\n",
        "        )\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(\n",
        "                in_features=embed_dim,\n",
        "                out_features=mlp_dim,\n",
        "                bias=True\n",
        "            ),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(\n",
        "                in_features=mlp_dim,\n",
        "                out_features=embed_dim,\n",
        "                bias=True\n",
        "            )\n",
        "        )\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x : [batch_size, num_patches, embed_dim]\n",
        "        \"\"\"\n",
        "        residual_1 = x\n",
        "        x_norm = self.layer_norm_1(input=x)\n",
        "        attention_output, _ = self.self_attention(\n",
        "            query=x_norm,\n",
        "            key=x_norm,\n",
        "            value=x_norm\n",
        "        )\n",
        "        x = attention_output + residual_1\n",
        "        residual_2 = x\n",
        "        x_norm = self.layer_norm_2(input=x)\n",
        "        mlp_output = self.mlp(x_norm)\n",
        "        x = mlp_output + residual_2\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Vision Transformer model class"
      ],
      "metadata": {
        "id": "Enle3YbwjFT-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yfdFX6vszUui"
      },
      "outputs": [],
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.patch_embedding = PatchEmbedding()\n",
        "        self.cls_token = nn.Parameter(\n",
        "            torch.randn(1, 1, embed_dim)\n",
        "        )\n",
        "        self.pos_embed = nn.Parameter(\n",
        "            torch.randn(1, (img_size // patch_size) ** 2 + 1, embed_dim)\n",
        "        )\n",
        "        self.transformer_layers = nn.Sequential(\n",
        "            *[TransformerBlock() for _ in range(transformer_units)]\n",
        "        )\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(\n",
        "                normalized_shape=embed_dim,\n",
        "                eps=1e-5,\n",
        "                elementwise_affine=True\n",
        "            ),\n",
        "            nn.Linear(\n",
        "                in_features=embed_dim,\n",
        "                out_features=10,\n",
        "                bias=True\n",
        "            )\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: Input images, shape [B, C, H, W]\n",
        "        Returns: Class logits, shape [B, num_classes]\n",
        "        \"\"\"\n",
        "        x = self.patch_embedding(x)\n",
        "        B = x.size(0)\n",
        "        cls_tokens = self.cls_token.expand(\n",
        "            B, -1, -1\n",
        "        )\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x = x + self.pos_embed\n",
        "        x = self.transformer_layers(x)\n",
        "        x = x[:, 0]\n",
        "        x = self.mlp_head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mgWEPtkPiN3V"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup device, model, optimizer, scheduler, and loss function"
      ],
      "metadata": {
        "id": "d8fepxtvjJLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "e98jyapliO5V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JZLw0P-SEBbi"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = VisionTransformer().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and validation loop with early stopping"
      ],
      "metadata": {
        "id": "BSW1wOegjLx3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQfP8U10wd3c",
        "outputId": "6a6242cf-1df9-42e7-be57-f9282d641cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "  Batch   1: Loss = 2.4523, Accuracy = 3.12%\n",
            "  Batch 101: Loss = 0.7898, Accuracy = 78.12%\n",
            "  Batch 201: Loss = 0.5979, Accuracy = 73.44%\n",
            "  Batch 301: Loss = 0.4584, Accuracy = 81.25%\n",
            "  Batch 401: Loss = 0.6835, Accuracy = 76.56%\n",
            "  Batch 501: Loss = 0.4989, Accuracy = 81.25%\n",
            "  Batch 601: Loss = 0.5479, Accuracy = 81.25%\n",
            "  Batch 701: Loss = 0.3869, Accuracy = 85.94%\n",
            "  Batch 801: Loss = 0.4943, Accuracy = 84.38%\n",
            "  Batch 901: Loss = 0.6060, Accuracy = 78.12%\n",
            "==> Epoch 1 Summary: Total Loss = 639.7198, Accuracy = 74.90%\n",
            "==> Validation: Loss = 0.4864, Accuracy = 82.21%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 2\n",
            "  Batch   1: Loss = 0.5172, Accuracy = 87.50%\n",
            "  Batch 101: Loss = 0.6866, Accuracy = 76.56%\n",
            "  Batch 201: Loss = 0.4278, Accuracy = 85.94%\n",
            "  Batch 301: Loss = 0.3614, Accuracy = 84.38%\n",
            "  Batch 401: Loss = 0.5254, Accuracy = 79.69%\n",
            "  Batch 501: Loss = 0.2055, Accuracy = 95.31%\n",
            "  Batch 601: Loss = 0.4335, Accuracy = 79.69%\n",
            "  Batch 701: Loss = 0.5141, Accuracy = 76.56%\n",
            "  Batch 801: Loss = 0.2747, Accuracy = 90.62%\n",
            "  Batch 901: Loss = 0.5423, Accuracy = 78.12%\n",
            "==> Epoch 2 Summary: Total Loss = 429.4909, Accuracy = 83.12%\n",
            "==> Validation: Loss = 0.4266, Accuracy = 84.47%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 3\n",
            "  Batch   1: Loss = 0.5826, Accuracy = 75.00%\n",
            "  Batch 101: Loss = 0.4207, Accuracy = 84.38%\n",
            "  Batch 201: Loss = 0.2834, Accuracy = 90.62%\n",
            "  Batch 301: Loss = 0.4211, Accuracy = 82.81%\n",
            "  Batch 401: Loss = 0.4581, Accuracy = 82.81%\n",
            "  Batch 501: Loss = 0.3862, Accuracy = 85.94%\n",
            "  Batch 601: Loss = 0.4116, Accuracy = 85.94%\n",
            "  Batch 701: Loss = 0.3111, Accuracy = 89.06%\n",
            "  Batch 801: Loss = 0.4450, Accuracy = 81.25%\n",
            "  Batch 901: Loss = 0.3212, Accuracy = 87.50%\n",
            "==> Epoch 3 Summary: Total Loss = 385.3002, Accuracy = 84.78%\n",
            "==> Validation: Loss = 0.4164, Accuracy = 84.19%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 4\n",
            "  Batch   1: Loss = 0.3960, Accuracy = 78.12%\n",
            "  Batch 101: Loss = 0.3169, Accuracy = 87.50%\n",
            "  Batch 201: Loss = 0.4664, Accuracy = 84.38%\n",
            "  Batch 301: Loss = 0.4143, Accuracy = 85.94%\n",
            "  Batch 401: Loss = 0.5197, Accuracy = 79.69%\n",
            "  Batch 501: Loss = 0.5857, Accuracy = 76.56%\n",
            "  Batch 601: Loss = 0.4155, Accuracy = 85.94%\n",
            "  Batch 701: Loss = 0.2432, Accuracy = 90.62%\n",
            "  Batch 801: Loss = 0.3495, Accuracy = 82.81%\n",
            "  Batch 901: Loss = 0.2622, Accuracy = 89.06%\n",
            "==> Epoch 4 Summary: Total Loss = 360.9357, Accuracy = 85.73%\n",
            "==> Validation: Loss = 0.3984, Accuracy = 85.29%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 5\n",
            "  Batch   1: Loss = 0.3446, Accuracy = 85.94%\n",
            "  Batch 101: Loss = 0.3835, Accuracy = 90.62%\n",
            "  Batch 201: Loss = 0.3667, Accuracy = 85.94%\n",
            "  Batch 301: Loss = 0.3722, Accuracy = 85.94%\n",
            "  Batch 401: Loss = 0.3242, Accuracy = 89.06%\n",
            "  Batch 501: Loss = 0.3559, Accuracy = 85.94%\n",
            "  Batch 601: Loss = 0.3985, Accuracy = 85.94%\n",
            "  Batch 701: Loss = 0.3722, Accuracy = 85.94%\n",
            "  Batch 801: Loss = 0.2091, Accuracy = 89.06%\n",
            "  Batch 901: Loss = 0.3026, Accuracy = 90.62%\n",
            "==> Epoch 5 Summary: Total Loss = 338.9901, Accuracy = 86.68%\n",
            "==> Validation: Loss = 0.3735, Accuracy = 85.84%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 6\n",
            "  Batch   1: Loss = 0.3268, Accuracy = 87.50%\n",
            "  Batch 101: Loss = 0.2859, Accuracy = 92.19%\n",
            "  Batch 201: Loss = 0.4508, Accuracy = 84.38%\n",
            "  Batch 301: Loss = 0.4739, Accuracy = 81.25%\n",
            "  Batch 401: Loss = 0.3751, Accuracy = 82.81%\n",
            "  Batch 501: Loss = 0.3084, Accuracy = 87.50%\n",
            "  Batch 601: Loss = 0.2294, Accuracy = 93.75%\n",
            "  Batch 701: Loss = 0.3699, Accuracy = 89.06%\n",
            "  Batch 801: Loss = 0.4210, Accuracy = 85.94%\n",
            "  Batch 901: Loss = 0.3533, Accuracy = 87.50%\n",
            "==> Epoch 6 Summary: Total Loss = 324.4230, Accuracy = 87.21%\n",
            "==> Validation: Loss = 0.3507, Accuracy = 87.11%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 7\n",
            "  Batch   1: Loss = 0.2965, Accuracy = 92.19%\n",
            "  Batch 101: Loss = 0.2728, Accuracy = 89.06%\n",
            "  Batch 201: Loss = 0.2111, Accuracy = 90.62%\n",
            "  Batch 301: Loss = 0.2875, Accuracy = 93.75%\n",
            "  Batch 401: Loss = 0.3925, Accuracy = 84.38%\n",
            "  Batch 501: Loss = 0.2901, Accuracy = 90.62%\n",
            "  Batch 601: Loss = 0.3343, Accuracy = 85.94%\n",
            "  Batch 701: Loss = 0.4022, Accuracy = 84.38%\n",
            "  Batch 801: Loss = 0.3812, Accuracy = 89.06%\n",
            "  Batch 901: Loss = 0.4049, Accuracy = 85.94%\n",
            "==> Epoch 7 Summary: Total Loss = 313.1928, Accuracy = 87.57%\n",
            "==> Validation: Loss = 0.3462, Accuracy = 87.05%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 8\n",
            "  Batch   1: Loss = 0.3552, Accuracy = 85.94%\n",
            "  Batch 101: Loss = 0.0886, Accuracy = 96.88%\n",
            "  Batch 201: Loss = 0.4847, Accuracy = 87.50%\n",
            "  Batch 301: Loss = 0.3309, Accuracy = 85.94%\n",
            "  Batch 401: Loss = 0.2608, Accuracy = 95.31%\n",
            "  Batch 501: Loss = 0.3277, Accuracy = 89.06%\n",
            "  Batch 601: Loss = 0.2778, Accuracy = 89.06%\n",
            "  Batch 701: Loss = 0.5042, Accuracy = 79.69%\n",
            "  Batch 801: Loss = 0.4292, Accuracy = 84.38%\n",
            "  Batch 901: Loss = 0.3578, Accuracy = 87.50%\n",
            "==> Epoch 8 Summary: Total Loss = 300.8898, Accuracy = 88.19%\n",
            "==> Validation: Loss = 0.3291, Accuracy = 88.18%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 9\n",
            "  Batch   1: Loss = 0.2786, Accuracy = 90.62%\n",
            "  Batch 101: Loss = 0.4142, Accuracy = 85.94%\n",
            "  Batch 201: Loss = 0.2675, Accuracy = 90.62%\n",
            "  Batch 301: Loss = 0.3185, Accuracy = 90.62%\n",
            "  Batch 401: Loss = 0.3331, Accuracy = 85.94%\n",
            "  Batch 501: Loss = 0.3171, Accuracy = 89.06%\n",
            "  Batch 601: Loss = 0.4211, Accuracy = 84.38%\n",
            "  Batch 701: Loss = 0.2902, Accuracy = 89.06%\n",
            "  Batch 801: Loss = 0.2453, Accuracy = 89.06%\n",
            "  Batch 901: Loss = 0.2246, Accuracy = 95.31%\n",
            "==> Epoch 9 Summary: Total Loss = 293.6876, Accuracy = 88.32%\n",
            "==> Validation: Loss = 0.3206, Accuracy = 88.34%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 10\n",
            "  Batch   1: Loss = 0.2858, Accuracy = 92.19%\n",
            "  Batch 101: Loss = 0.2603, Accuracy = 90.62%\n",
            "  Batch 201: Loss = 0.2711, Accuracy = 90.62%\n",
            "  Batch 301: Loss = 0.2278, Accuracy = 93.75%\n",
            "  Batch 401: Loss = 0.3352, Accuracy = 87.50%\n",
            "  Batch 501: Loss = 0.3987, Accuracy = 84.38%\n",
            "  Batch 601: Loss = 0.4380, Accuracy = 84.38%\n",
            "  Batch 701: Loss = 0.3183, Accuracy = 92.19%\n",
            "  Batch 801: Loss = 0.3271, Accuracy = 89.06%\n",
            "  Batch 901: Loss = 0.2897, Accuracy = 89.06%\n",
            "==> Epoch 10 Summary: Total Loss = 280.8070, Accuracy = 88.89%\n",
            "==> Validation: Loss = 0.3218, Accuracy = 87.93%\n",
            "\n",
            "Epoch 11\n",
            "  Batch   1: Loss = 0.3747, Accuracy = 84.38%\n",
            "  Batch 101: Loss = 0.2073, Accuracy = 92.19%\n",
            "  Batch 201: Loss = 0.4174, Accuracy = 82.81%\n",
            "  Batch 301: Loss = 0.3526, Accuracy = 89.06%\n",
            "  Batch 401: Loss = 0.3665, Accuracy = 89.06%\n",
            "  Batch 501: Loss = 0.2405, Accuracy = 92.19%\n",
            "  Batch 601: Loss = 0.2541, Accuracy = 90.62%\n",
            "  Batch 701: Loss = 0.3481, Accuracy = 87.50%\n",
            "  Batch 801: Loss = 0.2900, Accuracy = 92.19%\n",
            "  Batch 901: Loss = 0.2920, Accuracy = 85.94%\n",
            "==> Epoch 11 Summary: Total Loss = 275.3734, Accuracy = 89.05%\n",
            "==> Validation: Loss = 0.3260, Accuracy = 88.04%\n",
            "\n",
            "Epoch 12\n",
            "  Batch   1: Loss = 0.4269, Accuracy = 82.81%\n",
            "  Batch 101: Loss = 0.2695, Accuracy = 89.06%\n",
            "  Batch 201: Loss = 0.3589, Accuracy = 90.62%\n",
            "  Batch 301: Loss = 0.2553, Accuracy = 90.62%\n",
            "  Batch 401: Loss = 0.3047, Accuracy = 87.50%\n",
            "  Batch 501: Loss = 0.3356, Accuracy = 85.94%\n",
            "  Batch 601: Loss = 0.2612, Accuracy = 90.62%\n",
            "  Batch 701: Loss = 0.1670, Accuracy = 92.19%\n",
            "  Batch 801: Loss = 0.1785, Accuracy = 93.75%\n",
            "  Batch 901: Loss = 0.3403, Accuracy = 87.50%\n",
            "==> Epoch 12 Summary: Total Loss = 266.6681, Accuracy = 89.37%\n",
            "==> Validation: Loss = 0.3043, Accuracy = 88.94%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 13\n",
            "  Batch   1: Loss = 0.2875, Accuracy = 87.50%\n",
            "  Batch 101: Loss = 0.1228, Accuracy = 96.88%\n",
            "  Batch 201: Loss = 0.3382, Accuracy = 87.50%\n",
            "  Batch 301: Loss = 0.5456, Accuracy = 85.94%\n",
            "  Batch 401: Loss = 0.2394, Accuracy = 95.31%\n",
            "  Batch 501: Loss = 0.1787, Accuracy = 92.19%\n",
            "  Batch 601: Loss = 0.6017, Accuracy = 82.81%\n",
            "  Batch 701: Loss = 0.2534, Accuracy = 90.62%\n",
            "  Batch 801: Loss = 0.2842, Accuracy = 87.50%\n",
            "  Batch 901: Loss = 0.2613, Accuracy = 90.62%\n",
            "==> Epoch 13 Summary: Total Loss = 262.4091, Accuracy = 89.53%\n",
            "==> Validation: Loss = 0.2995, Accuracy = 89.21%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 14\n",
            "  Batch   1: Loss = 0.1947, Accuracy = 92.19%\n",
            "  Batch 101: Loss = 0.2591, Accuracy = 89.06%\n",
            "  Batch 201: Loss = 0.3697, Accuracy = 84.38%\n",
            "  Batch 301: Loss = 0.1529, Accuracy = 93.75%\n",
            "  Batch 401: Loss = 0.3846, Accuracy = 87.50%\n",
            "  Batch 501: Loss = 0.2030, Accuracy = 90.62%\n",
            "  Batch 601: Loss = 0.2899, Accuracy = 89.06%\n",
            "  Batch 701: Loss = 0.1700, Accuracy = 95.31%\n",
            "  Batch 801: Loss = 0.2283, Accuracy = 90.62%\n",
            "  Batch 901: Loss = 0.3134, Accuracy = 87.50%\n",
            "==> Epoch 14 Summary: Total Loss = 253.0164, Accuracy = 89.98%\n",
            "==> Validation: Loss = 0.2975, Accuracy = 89.17%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 15\n",
            "  Batch   1: Loss = 0.3120, Accuracy = 89.06%\n",
            "  Batch 101: Loss = 0.1580, Accuracy = 92.19%\n",
            "  Batch 201: Loss = 0.1880, Accuracy = 90.62%\n",
            "  Batch 301: Loss = 0.3194, Accuracy = 90.62%\n",
            "  Batch 401: Loss = 0.1947, Accuracy = 95.31%\n",
            "  Batch 501: Loss = 0.3533, Accuracy = 84.38%\n",
            "  Batch 601: Loss = 0.1155, Accuracy = 95.31%\n",
            "  Batch 701: Loss = 0.3075, Accuracy = 90.62%\n",
            "  Batch 801: Loss = 0.2783, Accuracy = 89.06%\n",
            "  Batch 901: Loss = 0.3794, Accuracy = 87.50%\n",
            "==> Epoch 15 Summary: Total Loss = 246.2501, Accuracy = 90.17%\n",
            "==> Validation: Loss = 0.2946, Accuracy = 89.27%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 16\n",
            "  Batch   1: Loss = 0.4159, Accuracy = 81.25%\n",
            "  Batch 101: Loss = 0.2071, Accuracy = 92.19%\n",
            "  Batch 201: Loss = 0.1578, Accuracy = 95.31%\n",
            "  Batch 301: Loss = 0.2365, Accuracy = 92.19%\n",
            "  Batch 401: Loss = 0.3269, Accuracy = 87.50%\n",
            "  Batch 501: Loss = 0.2475, Accuracy = 90.62%\n",
            "  Batch 601: Loss = 0.2432, Accuracy = 90.62%\n",
            "  Batch 701: Loss = 0.2269, Accuracy = 93.75%\n",
            "  Batch 801: Loss = 0.1965, Accuracy = 90.62%\n",
            "  Batch 901: Loss = 0.3692, Accuracy = 84.38%\n",
            "==> Epoch 16 Summary: Total Loss = 241.5502, Accuracy = 90.42%\n",
            "==> Validation: Loss = 0.2969, Accuracy = 88.87%\n",
            "\n",
            "Epoch 17\n",
            "  Batch   1: Loss = 0.3526, Accuracy = 82.81%\n",
            "  Batch 101: Loss = 0.4860, Accuracy = 89.06%\n",
            "  Batch 201: Loss = 0.2614, Accuracy = 93.75%\n",
            "  Batch 301: Loss = 0.1760, Accuracy = 95.31%\n",
            "  Batch 401: Loss = 0.2060, Accuracy = 92.19%\n",
            "  Batch 501: Loss = 0.3856, Accuracy = 85.94%\n",
            "  Batch 601: Loss = 0.1610, Accuracy = 96.88%\n",
            "  Batch 701: Loss = 0.2456, Accuracy = 92.19%\n",
            "  Batch 801: Loss = 0.1563, Accuracy = 93.75%\n",
            "  Batch 901: Loss = 0.2354, Accuracy = 90.62%\n",
            "==> Epoch 17 Summary: Total Loss = 235.5127, Accuracy = 90.71%\n",
            "==> Validation: Loss = 0.2838, Accuracy = 89.72%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 18\n",
            "  Batch   1: Loss = 0.3335, Accuracy = 85.94%\n",
            "  Batch 101: Loss = 0.1969, Accuracy = 89.06%\n",
            "  Batch 201: Loss = 0.2751, Accuracy = 90.62%\n",
            "  Batch 301: Loss = 0.1684, Accuracy = 93.75%\n",
            "  Batch 401: Loss = 0.1516, Accuracy = 92.19%\n",
            "  Batch 501: Loss = 0.1429, Accuracy = 93.75%\n",
            "  Batch 601: Loss = 0.3053, Accuracy = 92.19%\n",
            "  Batch 701: Loss = 0.2555, Accuracy = 85.94%\n",
            "  Batch 801: Loss = 0.3002, Accuracy = 87.50%\n",
            "  Batch 901: Loss = 0.2118, Accuracy = 90.62%\n",
            "==> Epoch 18 Summary: Total Loss = 230.2888, Accuracy = 90.86%\n",
            "==> Validation: Loss = 0.2767, Accuracy = 89.95%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 19\n",
            "  Batch   1: Loss = 0.2162, Accuracy = 92.19%\n",
            "  Batch 101: Loss = 0.2048, Accuracy = 92.19%\n",
            "  Batch 201: Loss = 0.3241, Accuracy = 85.94%\n",
            "  Batch 301: Loss = 0.2838, Accuracy = 87.50%\n",
            "  Batch 401: Loss = 0.3504, Accuracy = 82.81%\n",
            "  Batch 501: Loss = 0.2274, Accuracy = 92.19%\n",
            "  Batch 601: Loss = 0.2310, Accuracy = 90.62%\n",
            "  Batch 701: Loss = 0.2347, Accuracy = 92.19%\n",
            "  Batch 801: Loss = 0.1766, Accuracy = 90.62%\n",
            "  Batch 901: Loss = 0.2393, Accuracy = 87.50%\n",
            "==> Epoch 19 Summary: Total Loss = 223.6528, Accuracy = 91.10%\n",
            "==> Validation: Loss = 0.2733, Accuracy = 89.93%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 20\n",
            "  Batch   1: Loss = 0.4215, Accuracy = 85.94%\n",
            "  Batch 101: Loss = 0.3534, Accuracy = 84.38%\n",
            "  Batch 201: Loss = 0.1896, Accuracy = 90.62%\n",
            "  Batch 301: Loss = 0.2277, Accuracy = 89.06%\n",
            "  Batch 401: Loss = 0.2932, Accuracy = 89.06%\n",
            "  Batch 501: Loss = 0.1413, Accuracy = 95.31%\n",
            "  Batch 601: Loss = 0.2329, Accuracy = 92.19%\n",
            "  Batch 701: Loss = 0.2282, Accuracy = 90.62%\n",
            "  Batch 801: Loss = 0.1949, Accuracy = 95.31%\n",
            "  Batch 901: Loss = 0.3226, Accuracy = 89.06%\n",
            "==> Epoch 20 Summary: Total Loss = 218.7179, Accuracy = 91.27%\n",
            "==> Validation: Loss = 0.2830, Accuracy = 89.83%\n",
            "\n",
            "Epoch 21\n",
            "  Batch   1: Loss = 0.2420, Accuracy = 93.75%\n",
            "  Batch 101: Loss = 0.2024, Accuracy = 92.19%\n",
            "  Batch 201: Loss = 0.1833, Accuracy = 96.88%\n",
            "  Batch 301: Loss = 0.1992, Accuracy = 93.75%\n",
            "  Batch 401: Loss = 0.1758, Accuracy = 93.75%\n",
            "  Batch 501: Loss = 0.1709, Accuracy = 92.19%\n",
            "  Batch 601: Loss = 0.2074, Accuracy = 90.62%\n",
            "  Batch 701: Loss = 0.1080, Accuracy = 95.31%\n",
            "  Batch 801: Loss = 0.2404, Accuracy = 90.62%\n",
            "  Batch 901: Loss = 0.1707, Accuracy = 89.06%\n",
            "==> Epoch 21 Summary: Total Loss = 216.2022, Accuracy = 91.33%\n",
            "==> Validation: Loss = 0.2819, Accuracy = 89.98%\n",
            "\n",
            "Epoch 22\n",
            "  Batch   1: Loss = 0.2681, Accuracy = 90.62%\n",
            "  Batch 101: Loss = 0.2320, Accuracy = 93.75%\n",
            "  Batch 201: Loss = 0.3350, Accuracy = 85.94%\n",
            "  Batch 301: Loss = 0.1808, Accuracy = 90.62%\n",
            "  Batch 401: Loss = 0.2059, Accuracy = 92.19%\n",
            "  Batch 501: Loss = 0.1575, Accuracy = 93.75%\n",
            "  Batch 601: Loss = 0.2114, Accuracy = 92.19%\n",
            "  Batch 701: Loss = 0.2504, Accuracy = 90.62%\n",
            "  Batch 801: Loss = 0.1595, Accuracy = 92.19%\n",
            "  Batch 901: Loss = 0.1374, Accuracy = 95.31%\n",
            "==> Epoch 22 Summary: Total Loss = 209.6341, Accuracy = 91.59%\n",
            "==> Validation: Loss = 0.2731, Accuracy = 90.34%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 23\n",
            "  Batch   1: Loss = 0.2546, Accuracy = 90.62%\n",
            "  Batch 101: Loss = 0.3293, Accuracy = 89.06%\n",
            "  Batch 201: Loss = 0.1693, Accuracy = 90.62%\n",
            "  Batch 301: Loss = 0.2087, Accuracy = 92.19%\n",
            "  Batch 401: Loss = 0.1982, Accuracy = 92.19%\n",
            "  Batch 501: Loss = 0.1310, Accuracy = 96.88%\n",
            "  Batch 601: Loss = 0.2341, Accuracy = 90.62%\n",
            "  Batch 701: Loss = 0.1913, Accuracy = 89.06%\n",
            "  Batch 801: Loss = 0.1602, Accuracy = 93.75%\n",
            "  Batch 901: Loss = 0.3107, Accuracy = 89.06%\n",
            "==> Epoch 23 Summary: Total Loss = 202.8850, Accuracy = 91.89%\n",
            "==> Validation: Loss = 0.2750, Accuracy = 90.16%\n",
            "\n",
            "Epoch 24\n",
            "  Batch   1: Loss = 0.3467, Accuracy = 89.06%\n",
            "  Batch 101: Loss = 0.1365, Accuracy = 93.75%\n",
            "  Batch 201: Loss = 0.1194, Accuracy = 92.19%\n",
            "  Batch 301: Loss = 0.0757, Accuracy = 98.44%\n",
            "  Batch 401: Loss = 0.2106, Accuracy = 93.75%\n",
            "  Batch 501: Loss = 0.2312, Accuracy = 87.50%\n",
            "  Batch 601: Loss = 0.2001, Accuracy = 89.06%\n",
            "  Batch 701: Loss = 0.2019, Accuracy = 92.19%\n",
            "  Batch 801: Loss = 0.4204, Accuracy = 85.94%\n",
            "  Batch 901: Loss = 0.2180, Accuracy = 90.62%\n",
            "==> Epoch 24 Summary: Total Loss = 201.2358, Accuracy = 91.92%\n",
            "==> Validation: Loss = 0.2686, Accuracy = 90.41%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 25\n",
            "  Batch   1: Loss = 0.0873, Accuracy = 98.44%\n",
            "  Batch 101: Loss = 0.1594, Accuracy = 95.31%\n",
            "  Batch 201: Loss = 0.2080, Accuracy = 89.06%\n",
            "  Batch 301: Loss = 0.2269, Accuracy = 89.06%\n",
            "  Batch 401: Loss = 0.1054, Accuracy = 96.88%\n",
            "  Batch 501: Loss = 0.1812, Accuracy = 92.19%\n",
            "  Batch 601: Loss = 0.2396, Accuracy = 90.62%\n",
            "  Batch 701: Loss = 0.1385, Accuracy = 95.31%\n",
            "  Batch 801: Loss = 0.3651, Accuracy = 84.38%\n",
            "  Batch 901: Loss = 0.3943, Accuracy = 78.12%\n",
            "==> Epoch 25 Summary: Total Loss = 197.2892, Accuracy = 92.13%\n",
            "==> Validation: Loss = 0.2652, Accuracy = 90.66%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 26\n",
            "  Batch   1: Loss = 0.2157, Accuracy = 87.50%\n",
            "  Batch 101: Loss = 0.2007, Accuracy = 93.75%\n",
            "  Batch 201: Loss = 0.1236, Accuracy = 93.75%\n",
            "  Batch 301: Loss = 0.2960, Accuracy = 85.94%\n",
            "  Batch 401: Loss = 0.2592, Accuracy = 89.06%\n",
            "  Batch 501: Loss = 0.1339, Accuracy = 93.75%\n",
            "  Batch 601: Loss = 0.1480, Accuracy = 96.88%\n",
            "  Batch 701: Loss = 0.1690, Accuracy = 92.19%\n",
            "  Batch 801: Loss = 0.2834, Accuracy = 90.62%\n",
            "  Batch 901: Loss = 0.2852, Accuracy = 85.94%\n",
            "==> Epoch 26 Summary: Total Loss = 191.2115, Accuracy = 92.34%\n",
            "==> Validation: Loss = 0.2771, Accuracy = 90.17%\n",
            "\n",
            "Epoch 27\n",
            "  Batch   1: Loss = 0.1745, Accuracy = 93.75%\n",
            "  Batch 101: Loss = 0.1609, Accuracy = 92.19%\n",
            "  Batch 201: Loss = 0.1555, Accuracy = 93.75%\n",
            "  Batch 301: Loss = 0.2802, Accuracy = 93.75%\n",
            "  Batch 401: Loss = 0.2187, Accuracy = 92.19%\n",
            "  Batch 501: Loss = 0.2542, Accuracy = 87.50%\n",
            "  Batch 601: Loss = 0.2135, Accuracy = 89.06%\n",
            "  Batch 701: Loss = 0.2182, Accuracy = 89.06%\n",
            "  Batch 801: Loss = 0.0891, Accuracy = 96.88%\n",
            "  Batch 901: Loss = 0.2531, Accuracy = 92.19%\n",
            "==> Epoch 27 Summary: Total Loss = 188.5197, Accuracy = 92.38%\n",
            "==> Validation: Loss = 0.2793, Accuracy = 90.03%\n",
            "\n",
            "Epoch 28\n",
            "  Batch   1: Loss = 0.1114, Accuracy = 95.31%\n",
            "  Batch 101: Loss = 0.2358, Accuracy = 90.62%\n",
            "  Batch 201: Loss = 0.1669, Accuracy = 93.75%\n",
            "  Batch 301: Loss = 0.1858, Accuracy = 93.75%\n",
            "  Batch 401: Loss = 0.1513, Accuracy = 92.19%\n",
            "  Batch 501: Loss = 0.1466, Accuracy = 96.88%\n",
            "  Batch 601: Loss = 0.1110, Accuracy = 93.75%\n",
            "  Batch 701: Loss = 0.1813, Accuracy = 90.62%\n",
            "  Batch 801: Loss = 0.1027, Accuracy = 96.88%\n",
            "  Batch 901: Loss = 0.1246, Accuracy = 93.75%\n",
            "==> Epoch 28 Summary: Total Loss = 185.1290, Accuracy = 92.53%\n",
            "==> Validation: Loss = 0.2748, Accuracy = 90.40%\n",
            "\n",
            "Epoch 29\n",
            "  Batch   1: Loss = 0.1749, Accuracy = 93.75%\n",
            "  Batch 101: Loss = 0.1587, Accuracy = 89.06%\n",
            "  Batch 201: Loss = 0.2509, Accuracy = 90.62%\n",
            "  Batch 301: Loss = 0.2440, Accuracy = 92.19%\n",
            "  Batch 401: Loss = 0.2959, Accuracy = 90.62%\n",
            "  Batch 501: Loss = 0.2328, Accuracy = 89.06%\n",
            "  Batch 601: Loss = 0.2531, Accuracy = 92.19%\n",
            "  Batch 701: Loss = 0.2781, Accuracy = 90.62%\n",
            "  Batch 801: Loss = 0.1266, Accuracy = 96.88%\n",
            "  Batch 901: Loss = 0.1606, Accuracy = 90.62%\n",
            "==> Epoch 29 Summary: Total Loss = 178.1083, Accuracy = 92.95%\n",
            "==> Validation: Loss = 0.2579, Accuracy = 90.77%\n",
            "  Best model saved.\n",
            "\n",
            "Epoch 30\n",
            "  Batch   1: Loss = 0.1598, Accuracy = 93.75%\n",
            "  Batch 101: Loss = 0.2063, Accuracy = 90.62%\n",
            "  Batch 201: Loss = 0.2695, Accuracy = 89.06%\n",
            "  Batch 301: Loss = 0.1370, Accuracy = 96.88%\n",
            "  Batch 401: Loss = 0.2524, Accuracy = 84.38%\n",
            "  Batch 501: Loss = 0.1148, Accuracy = 96.88%\n",
            "  Batch 601: Loss = 0.1963, Accuracy = 90.62%\n",
            "  Batch 701: Loss = 0.1638, Accuracy = 93.75%\n",
            "  Batch 801: Loss = 0.1764, Accuracy = 90.62%\n",
            "  Batch 901: Loss = 0.1694, Accuracy = 90.62%\n",
            "==> Epoch 30 Summary: Total Loss = 176.9955, Accuracy = 92.91%\n",
            "==> Validation: Loss = 0.2646, Accuracy = 90.66%\n",
            "\n",
            "Epoch 31\n",
            "  Batch   1: Loss = 0.1654, Accuracy = 90.62%\n",
            "  Batch 101: Loss = 0.1647, Accuracy = 93.75%\n",
            "  Batch 201: Loss = 0.2268, Accuracy = 89.06%\n",
            "  Batch 301: Loss = 0.2639, Accuracy = 85.94%\n",
            "  Batch 401: Loss = 0.2203, Accuracy = 90.62%\n",
            "  Batch 501: Loss = 0.2088, Accuracy = 93.75%\n",
            "  Batch 601: Loss = 0.1125, Accuracy = 98.44%\n",
            "  Batch 701: Loss = 0.1120, Accuracy = 93.75%\n",
            "  Batch 801: Loss = 0.1581, Accuracy = 95.31%\n",
            "  Batch 901: Loss = 0.2692, Accuracy = 85.94%\n",
            "==> Epoch 31 Summary: Total Loss = 169.5150, Accuracy = 93.16%\n",
            "==> Validation: Loss = 0.2778, Accuracy = 90.22%\n",
            "\n",
            "Epoch 32\n",
            "  Batch   1: Loss = 0.1412, Accuracy = 93.75%\n",
            "  Batch 101: Loss = 0.1668, Accuracy = 90.62%\n",
            "  Batch 201: Loss = 0.1519, Accuracy = 95.31%\n",
            "  Batch 301: Loss = 0.1732, Accuracy = 89.06%\n",
            "  Batch 401: Loss = 0.1792, Accuracy = 93.75%\n",
            "  Batch 501: Loss = 0.1182, Accuracy = 95.31%\n",
            "  Batch 601: Loss = 0.2571, Accuracy = 87.50%\n",
            "  Batch 701: Loss = 0.1241, Accuracy = 93.75%\n",
            "  Batch 801: Loss = 0.2407, Accuracy = 93.75%\n",
            "  Batch 901: Loss = 0.1813, Accuracy = 92.19%\n",
            "==> Epoch 32 Summary: Total Loss = 166.5064, Accuracy = 93.20%\n",
            "==> Validation: Loss = 0.2671, Accuracy = 90.82%\n",
            "\n",
            "Epoch 33\n",
            "  Batch   1: Loss = 0.1075, Accuracy = 98.44%\n",
            "  Batch 101: Loss = 0.2399, Accuracy = 93.75%\n",
            "  Batch 201: Loss = 0.1880, Accuracy = 90.62%\n",
            "  Batch 301: Loss = 0.1322, Accuracy = 98.44%\n",
            "  Batch 401: Loss = 0.1060, Accuracy = 95.31%\n",
            "  Batch 501: Loss = 0.1842, Accuracy = 93.75%\n",
            "  Batch 601: Loss = 0.1329, Accuracy = 93.75%\n",
            "  Batch 701: Loss = 0.1855, Accuracy = 92.19%\n",
            "  Batch 801: Loss = 0.2819, Accuracy = 87.50%\n",
            "  Batch 901: Loss = 0.2582, Accuracy = 93.75%\n",
            "==> Epoch 33 Summary: Total Loss = 163.1033, Accuracy = 93.45%\n",
            "==> Validation: Loss = 0.2644, Accuracy = 91.13%\n",
            "\n",
            "Epoch 34\n",
            "  Batch   1: Loss = 0.1958, Accuracy = 92.19%\n",
            "  Batch 101: Loss = 0.1073, Accuracy = 95.31%\n",
            "  Batch 201: Loss = 0.2216, Accuracy = 90.62%\n",
            "  Batch 301: Loss = 0.1736, Accuracy = 95.31%\n",
            "  Batch 401: Loss = 0.1656, Accuracy = 92.19%\n",
            "  Batch 501: Loss = 0.1337, Accuracy = 95.31%\n",
            "  Batch 601: Loss = 0.0992, Accuracy = 98.44%\n",
            "  Batch 701: Loss = 0.3228, Accuracy = 92.19%\n",
            "  Batch 801: Loss = 0.1651, Accuracy = 90.62%\n",
            "  Batch 901: Loss = 0.0391, Accuracy = 98.44%\n",
            "==> Epoch 34 Summary: Total Loss = 157.4971, Accuracy = 93.67%\n",
            "==> Validation: Loss = 0.2780, Accuracy = 90.28%\n",
            "\n",
            "Epoch 35\n",
            "  Batch   1: Loss = 0.0519, Accuracy = 98.44%\n",
            "  Batch 101: Loss = 0.0669, Accuracy = 95.31%\n",
            "  Batch 201: Loss = 0.0832, Accuracy = 98.44%\n",
            "  Batch 301: Loss = 0.1505, Accuracy = 95.31%\n",
            "  Batch 401: Loss = 0.2856, Accuracy = 92.19%\n",
            "  Batch 501: Loss = 0.1726, Accuracy = 90.62%\n",
            "  Batch 601: Loss = 0.1655, Accuracy = 93.75%\n",
            "  Batch 701: Loss = 0.1399, Accuracy = 92.19%\n",
            "  Batch 801: Loss = 0.2792, Accuracy = 90.62%\n",
            "  Batch 901: Loss = 0.1312, Accuracy = 95.31%\n",
            "==> Epoch 35 Summary: Total Loss = 155.4721, Accuracy = 93.66%\n",
            "==> Validation: Loss = 0.2648, Accuracy = 91.08%\n",
            "\n",
            "Epoch 36\n",
            "  Batch   1: Loss = 0.1388, Accuracy = 95.31%\n",
            "  Batch 101: Loss = 0.1031, Accuracy = 95.31%\n",
            "  Batch 201: Loss = 0.1885, Accuracy = 93.75%\n",
            "  Batch 301: Loss = 0.1811, Accuracy = 89.06%\n",
            "  Batch 401: Loss = 0.1372, Accuracy = 95.31%\n",
            "  Batch 501: Loss = 0.1380, Accuracy = 95.31%\n",
            "  Batch 601: Loss = 0.0766, Accuracy = 96.88%\n",
            "  Batch 701: Loss = 0.0917, Accuracy = 95.31%\n",
            "  Batch 801: Loss = 0.1694, Accuracy = 93.75%\n",
            "  Batch 901: Loss = 0.1435, Accuracy = 93.75%\n",
            "==> Epoch 36 Summary: Total Loss = 151.5152, Accuracy = 93.86%\n",
            "==> Validation: Loss = 0.2622, Accuracy = 91.07%\n",
            "\n",
            "Epoch 37\n",
            "  Batch   1: Loss = 0.1280, Accuracy = 95.31%\n",
            "  Batch 101: Loss = 0.1547, Accuracy = 93.75%\n",
            "  Batch 201: Loss = 0.1903, Accuracy = 92.19%\n",
            "  Batch 301: Loss = 0.1545, Accuracy = 93.75%\n",
            "  Batch 401: Loss = 0.3556, Accuracy = 85.94%\n",
            "  Batch 501: Loss = 0.1667, Accuracy = 95.31%\n",
            "  Batch 601: Loss = 0.0713, Accuracy = 98.44%\n",
            "  Batch 701: Loss = 0.2245, Accuracy = 89.06%\n",
            "  Batch 801: Loss = 0.1748, Accuracy = 92.19%\n",
            "  Batch 901: Loss = 0.2183, Accuracy = 90.62%\n",
            "==> Epoch 37 Summary: Total Loss = 147.6023, Accuracy = 94.01%\n",
            "==> Validation: Loss = 0.2751, Accuracy = 90.84%\n",
            "\n",
            "Epoch 38\n",
            "  Batch   1: Loss = 0.1401, Accuracy = 96.88%\n",
            "  Batch 101: Loss = 0.0487, Accuracy = 98.44%\n",
            "  Batch 201: Loss = 0.0935, Accuracy = 96.88%\n",
            "  Batch 301: Loss = 0.1201, Accuracy = 95.31%\n",
            "  Batch 401: Loss = 0.1212, Accuracy = 93.75%\n",
            "  Batch 501: Loss = 0.2197, Accuracy = 92.19%\n",
            "  Batch 601: Loss = 0.1084, Accuracy = 92.19%\n",
            "  Batch 701: Loss = 0.2396, Accuracy = 89.06%\n",
            "  Batch 801: Loss = 0.1614, Accuracy = 90.62%\n",
            "  Batch 901: Loss = 0.1945, Accuracy = 93.75%\n",
            "==> Epoch 38 Summary: Total Loss = 144.4590, Accuracy = 94.24%\n",
            "==> Validation: Loss = 0.2672, Accuracy = 90.99%\n",
            "\n",
            "Epoch 39\n",
            "  Batch   1: Loss = 0.1168, Accuracy = 95.31%\n",
            "  Batch 101: Loss = 0.1329, Accuracy = 95.31%\n",
            "  Batch 201: Loss = 0.2178, Accuracy = 93.75%\n",
            "  Batch 301: Loss = 0.1246, Accuracy = 92.19%\n",
            "  Batch 401: Loss = 0.0912, Accuracy = 96.88%\n",
            "  Batch 501: Loss = 0.1545, Accuracy = 92.19%\n",
            "  Batch 601: Loss = 0.1401, Accuracy = 93.75%\n",
            "  Batch 701: Loss = 0.1209, Accuracy = 95.31%\n",
            "  Batch 801: Loss = 0.1080, Accuracy = 98.44%\n",
            "  Batch 901: Loss = 0.0884, Accuracy = 98.44%\n",
            "==> Epoch 39 Summary: Total Loss = 139.5324, Accuracy = 94.38%\n",
            "==> Validation: Loss = 0.2662, Accuracy = 91.00%\n",
            "\n",
            "Epoch 40\n",
            "  Batch   1: Loss = 0.1911, Accuracy = 92.19%\n",
            "  Batch 101: Loss = 0.1923, Accuracy = 93.75%\n",
            "  Batch 201: Loss = 0.1098, Accuracy = 93.75%\n",
            "  Batch 301: Loss = 0.1555, Accuracy = 93.75%\n",
            "  Batch 401: Loss = 0.0941, Accuracy = 96.88%\n",
            "  Batch 501: Loss = 0.1379, Accuracy = 95.31%\n",
            "  Batch 601: Loss = 0.1126, Accuracy = 93.75%\n",
            "  Batch 701: Loss = 0.1455, Accuracy = 93.75%\n",
            "  Batch 801: Loss = 0.0786, Accuracy = 96.88%\n",
            "  Batch 901: Loss = 0.1418, Accuracy = 96.88%\n",
            "==> Epoch 40 Summary: Total Loss = 136.8258, Accuracy = 94.38%\n",
            "==> Validation: Loss = 0.2642, Accuracy = 90.97%\n",
            "\n",
            "Epoch 41\n",
            "  Batch   1: Loss = 0.1012, Accuracy = 98.44%\n",
            "  Batch 101: Loss = 0.1371, Accuracy = 95.31%\n",
            "  Batch 201: Loss = 0.1794, Accuracy = 93.75%\n",
            "  Batch 301: Loss = 0.0927, Accuracy = 96.88%\n",
            "  Batch 401: Loss = 0.2705, Accuracy = 92.19%\n",
            "  Batch 501: Loss = 0.1358, Accuracy = 96.88%\n",
            "  Batch 601: Loss = 0.2088, Accuracy = 92.19%\n",
            "  Batch 701: Loss = 0.1161, Accuracy = 95.31%\n",
            "  Batch 801: Loss = 0.3274, Accuracy = 90.62%\n",
            "  Batch 901: Loss = 0.1540, Accuracy = 93.75%\n",
            "==> Epoch 41 Summary: Total Loss = 131.2091, Accuracy = 94.81%\n",
            "==> Validation: Loss = 0.2692, Accuracy = 91.12%\n",
            "Early stopping triggered at epoch 41\n"
          ]
        }
      ],
      "source": [
        "best_val_loss = float('inf')\n",
        "patience = 12\n",
        "counter = 0\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_epoch = 0\n",
        "    total_epoch = 0\n",
        "    print(f\"\\nEpoch {epoch+1}\")\n",
        "    for batch_idx, (images, labels) in enumerate(train_data):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct = (preds == labels).sum().item()\n",
        "        correct_epoch += correct\n",
        "        total_epoch += labels.size(0)\n",
        "        if batch_idx % 100 == 0:\n",
        "            batch_acc = 100.0 * correct / labels.size(0)\n",
        "            print(f\"  Batch {batch_idx+1:3d}: Loss = {loss.item():.4f}, Accuracy = {batch_acc:.2f}%\")\n",
        "    epoch_acc = 100.0 * correct_epoch / total_epoch\n",
        "    print(f\"==> Epoch {epoch+1} Summary: Total Loss = {total_loss:.4f}, Accuracy = {epoch_acc:.2f}%\")\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_data:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "    val_loss /= len(val_data)\n",
        "    val_acc = 100.0 * val_correct / val_total\n",
        "    print(f\"==> Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.2f}%\")\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0\n",
        "        torch.save(model.state_dict(), 'best_vit_model.pth')\n",
        "        print(\"  Best model saved.\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform model evaluation"
      ],
      "metadata": {
        "id": "mt7GS2F4jU1t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDG1H1p029O6",
        "outputId": "ee0465bd-af00-4bfc-d939-d727720e2b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Final Validation Accuracy = 90.77%\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('best_vit_model.pth'))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "val_correct = 0\n",
        "val_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_data:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        val_correct += (preds == labels).sum().item()\n",
        "        val_total += labels.size(0)\n",
        "final_val_acc = 100.0 * val_correct / val_total\n",
        "print(f\"\\n Final Validation Accuracy = {final_val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# metrics"
      ],
      "metadata": {
        "id": "e1x49RDJjYUg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05d8Jrp1_Lyz",
        "outputId": "8996b815-7d1d-47e3-824b-19cc9a6599b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.84      0.85      1000\n",
            "           1       0.98      0.98      0.98      1000\n",
            "           2       0.86      0.83      0.85      1000\n",
            "           3       0.89      0.93      0.91      1000\n",
            "           4       0.86      0.85      0.85      1000\n",
            "           5       0.98      0.96      0.97      1000\n",
            "           6       0.75      0.77      0.76      1000\n",
            "           7       0.94      0.97      0.96      1000\n",
            "           8       0.97      0.98      0.98      1000\n",
            "           9       0.97      0.96      0.96      1000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_data:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "print(classification_report(all_labels, all_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-wwjJ2Ke_SPb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}